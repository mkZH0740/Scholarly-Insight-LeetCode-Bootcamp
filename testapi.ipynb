{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Features:\n",
    "- Number of Results\n",
    "- Sortby and Sortorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "#from pandarallel import pandarallel\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_maker(attributes,advanced_search=False):\n",
    "\n",
    "    \n",
    "    \n",
    "    return search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "url = 'http://export.arxiv.org/api/query?'\n",
    "\n",
    "\n",
    "max_res=6\n",
    "start=0\n",
    "\n",
    "advanced_search = False\n",
    "if advanced_search:\n",
    "    \n",
    "    '''\n",
    "    Attributes accepted,\n",
    "    Logic Type: AND, OR, ANDNOT\n",
    "    ti: Title\n",
    "    au: Author\n",
    "    abs: Abstract\n",
    "    co: Comment\n",
    "    jr: Journal Reference\n",
    "    cat: Subject Category\n",
    "    rn: Report Number\n",
    "    all: Search in all\n",
    "    '''\n",
    "    title,author,abstract,comment,jr,cat,rn = None,None,None,None,None,None,None\n",
    "    \n",
    "    attributes={'ti':title,\n",
    "                'au':author,\n",
    "                'abs':abstract,\n",
    "                'co':comment,\n",
    "                'jr':jr,\n",
    "                'cat':cat,\n",
    "                'rn':rn}\n",
    "else:\n",
    "    all_search=None\n",
    "    attributes={'all':all_search}\n",
    "\n",
    "data={'search_query':search_query_maker(attributes),\n",
    "      'start':start,\n",
    "      'max_results':max_res}\n",
    "\n",
    "resp = requests.get(url,params=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3Ddeep%20learning%26id_list%3D%26start%3D0%26max_results%3D6\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=deep learning&amp;id_list=&amp;start=0&amp;max_results=6</title>\\n  <id>http://arxiv.org/api/3aeq26OMBC+MEqazIWyrrgVQp04</id>\\n  <updated>2024-03-18T00:00:00-04:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">336888</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">6</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/1805.08355v1</id>\\n    <updated>2018-05-22T02:12:33Z</updated>\\n    <published>2018-05-22T02:12:33Z</published>\\n    <title>Opening the black box of deep learning</title>\\n    <summary>  The great success of deep learning shows that its technology contains\\nprofound truth, and understanding its internal mechanism not only has important\\nimplications for the development of its technology and effective application in\\nvarious fields, but also provides meaningful insights into the understanding of\\nhuman brain mechanism. At present, most of the theoretical research on deep\\nlearning is based on mathematics. This dissertation proposes that the neural\\nnetwork of deep learning is a physical system, examines deep learning from\\nthree different perspectives: microscopic, macroscopic, and physical world\\nviews, answers multiple theoretical puzzles in deep learning by using physics\\nprinciples. For example, from the perspective of quantum mechanics and\\nstatistical physics, this dissertation presents the calculation methods for\\nconvolution calculation, pooling, normalization, and Restricted Boltzmann\\nMachine, as well as the selection of cost functions, explains why deep learning\\nmust be deep, what characteristics are learned in deep learning, why\\nConvolutional Neural Networks do not have to be trained layer by layer, and the\\nlimitations of deep learning, etc., and proposes the theoretical direction and\\nbasis for the further development of deep learning now and in the future. The\\nbrilliance of physics flashes in deep learning, we try to establish the deep\\nlearning technology based on the scientific theory of physics.\\n</summary>\\n    <author>\\n      <name>Dian Lei</name>\\n    </author>\\n    <author>\\n      <name>Xiaoxiao Chen</name>\\n    </author>\\n    <author>\\n      <name>Jianfei Zhao</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1805.08355v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1805.08355v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1806.01756v1</id>\\n    <updated>2018-06-05T15:50:30Z</updated>\\n    <published>2018-06-05T15:50:30Z</published>\\n    <title>Concept-Oriented Deep Learning</title>\\n    <summary>  Concepts are the foundation of human deep learning, understanding, and\\nknowledge integration and transfer. We propose concept-oriented deep learning\\n(CODL) which extends (machine) deep learning with concept representations and\\nconceptual understanding capability. CODL addresses some of the major\\nlimitations of deep learning: interpretability, transferability, contextual\\nadaptation, and requirement for lots of labeled training data. We discuss the\\nmajor aspects of CODL including concept graph, concept representations, concept\\nexemplars, and concept representation learning systems supporting incremental\\nand continual learning.\\n</summary>\\n    <author>\\n      <name>Daniel T Chang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1806.01756v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1806.01756v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1908.02130v1</id>\\n    <updated>2019-07-30T16:57:38Z</updated>\\n    <published>2019-07-30T16:57:38Z</published>\\n    <title>Deep learning research landscape &amp; roadmap in a nutshell: past, present\\n  and future -- Towards deep cortical learning</title>\\n    <summary>  The past, present and future of deep learning is presented in this work.\\nGiven this landscape &amp; roadmap, we predict that deep cortical learning will be\\nthe convergence of deep learning &amp; cortical learning which builds an artificial\\ncortical column ultimately.\\n</summary>\\n    <author>\\n      <name>Aras R. Dargazany</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1908.02130v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1908.02130v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.NE\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1812.05448v4</id>\\n    <updated>2021-01-13T01:29:33Z</updated>\\n    <published>2018-11-08T07:59:23Z</published>\\n    <title>A First Look at Deep Learning Apps on Smartphones</title>\\n    <summary>  We are in the dawn of deep learning explosion for smartphones. To bridge the\\ngap between research and practice, we present the first empirical study on\\n16,500 the most popular Android apps, demystifying how smartphone apps exploit\\ndeep learning in the wild. To this end, we build a new static tool that\\ndissects apps and analyzes their deep learning functions. Our study answers\\nthreefold questions: what are the early adopter apps of deep learning, what do\\nthey use deep learning for, and how do their deep learning models look like.\\nOur study has strong implications for app developers, smartphone vendors, and\\ndeep learning R\\\\&amp;D. On one hand, our findings paint a promising picture of deep\\nlearning for smartphones, showing the prosperity of mobile deep learning\\nframeworks as well as the prosperity of apps building their cores atop deep\\nlearning. On the other hand, our findings urge optimizations on deep learning\\nmodels deployed on smartphones, the protection of these models, and validation\\nof research ideas on these models.\\n</summary>\\n    <author>\\n      <name>Mengwei Xu</name>\\n    </author>\\n    <author>\\n      <name>Jiawei Liu</name>\\n    </author>\\n    <author>\\n      <name>Yuanqiang Liu</name>\\n    </author>\\n    <author>\\n      <name>Felix Xiaozhu Lin</name>\\n    </author>\\n    <author>\\n      <name>Yunxin Liu</name>\\n    </author>\\n    <author>\\n      <name>Xuanzhe Liu</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1812.05448v4\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1812.05448v4\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1705.03921v1</id>\\n    <updated>2017-05-10T18:52:26Z</updated>\\n    <published>2017-05-10T18:52:26Z</published>\\n    <title>Why &amp; When Deep Learning Works: Looking Inside Deep Learnings</title>\\n    <summary>  The Intel Collaborative Research Institute for Computational Intelligence\\n(ICRI-CI) has been heavily supporting Machine Learning and Deep Learning\\nresearch from its foundation in 2012. We have asked six leading ICRI-CI Deep\\nLearning researchers to address the challenge of \"Why &amp; When Deep Learning\\nworks\", with the goal of looking inside Deep Learning, providing insights on\\nhow deep networks function, and uncovering key observations on their\\nexpressiveness, limitations, and potential. The output of this challenge\\nresulted in five papers that address different facets of deep learning. These\\ndifferent facets include a high-level understating of why and when deep\\nnetworks work (and do not work), the impact of geometry on the expressiveness\\nof deep networks, and making deep networks interpretable.\\n</summary>\\n    <author>\\n      <name>Ronny Ronen</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This paper is the preface part of the \"Why &amp; When Deep Learning works\\n  looking inside Deep Learning\" ICRI-CI paper bundle</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1705.03921v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1705.03921v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/1901.02354v2</id>\\n    <updated>2019-01-13T17:20:05Z</updated>\\n    <published>2019-01-06T14:32:45Z</published>\\n    <title>Geometrization of deep networks for the interpretability of deep\\n  learning systems</title>\\n    <summary>  How to understand deep learning systems remains an open problem. In this\\npaper we propose that the answer may lie in the geometrization of deep\\nnetworks. Geometrization is a bridge to connect physics, geometry, deep network\\nand quantum computation and this may result in a new scheme to reveal the rule\\nof the physical world. By comparing the geometry of image matching and deep\\nnetworks, we show that geometrization of deep networks can be used to\\nunderstand existing deep learning systems and it may also help to solve the\\ninterpretability problem of deep learning systems.\\n</summary>\\n    <author>\\n      <name>Xiao Dong</name>\\n    </author>\\n    <author>\\n      <name>Ling Zhou</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, draft version</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1901.02354v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1901.02354v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "root =ET.fromstring(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element '{http://www.w3.org/2005/Atom}id' at 0x000001F525923FB0>, <Element '{http://www.w3.org/2005/Atom}updated' at 0x000001F525950090>, <Element '{http://www.w3.org/2005/Atom}published' at 0x000001F525950180>, <Element '{http://www.w3.org/2005/Atom}title' at 0x000001F525950360>, <Element '{http://www.w3.org/2005/Atom}summary' at 0x000001F525950270>, <Element '{http://www.w3.org/2005/Atom}author' at 0x000001F5259504A0>, <Element '{http://www.w3.org/2005/Atom}author' at 0x000001F525950590>, <Element '{http://www.w3.org/2005/Atom}author' at 0x000001F525950630>, <Element '{http://www.w3.org/2005/Atom}link' at 0x000001F525950680>, <Element '{http://www.w3.org/2005/Atom}link' at 0x000001F525950720>, <Element '{http://arxiv.org/schemas/atom}primary_category' at 0x000001F525950810>, <Element '{http://www.w3.org/2005/Atom}category' at 0x000001F525950900>, <Element '{http://www.w3.org/2005/Atom}category' at 0x000001F5259509A0>]\n"
     ]
    }
   ],
   "source": [
    "print([child for child in root[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {http://www.w3.org/2005/Atom}link None\n",
      "1 {http://www.w3.org/2005/Atom}title ArXiv Query: search_query=deep learning&id_list=&start=0&max_results=6\n",
      "2 {http://www.w3.org/2005/Atom}id http://arxiv.org/api/3aeq26OMBC+MEqazIWyrrgVQp04\n",
      "3 {http://www.w3.org/2005/Atom}updated 2024-03-18T00:00:00-04:00\n",
      "4 {http://a9.com/-/spec/opensearch/1.1/}totalResults 336888\n",
      "5 {http://a9.com/-/spec/opensearch/1.1/}startIndex 0\n",
      "6 {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage 6\n",
      "7 {http://www.w3.org/2005/Atom}entry \n",
      "    \n",
      "8 {http://www.w3.org/2005/Atom}entry \n",
      "    \n",
      "9 {http://www.w3.org/2005/Atom}entry \n",
      "    \n",
      "10 {http://www.w3.org/2005/Atom}entry \n",
      "    \n",
      "11 {http://www.w3.org/2005/Atom}entry \n",
      "    \n",
      "12 {http://www.w3.org/2005/Atom}entry \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for i,child in enumerate(root):\n",
    "    print(i,child.tag, child.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "    rank = country.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "    #name = country.get('name')\n",
    "    print(rank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
